# The Llama Cloud API key.
# LLAMA_CLOUD_API_KEY=

# The provider for the AI models to use.
MODEL_PROVIDER=openai

# The name of LLM model to use.
MODEL=gpt-4o

# Name of the embedding model to use.
EMBEDDING_MODEL=text-embedding-3-large

# Dimension of the embedding model to use.
EMBEDDING_DIM=1024

# The questions to help users get started (multi-line).
# CONVERSATION_STARTERS=

# The OpenAI API key to use.
OPENAI_API_KEY=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

# Temperature for sampling from the model.
# LLM_TEMPERATURE=

# Maximum number of tokens to generate.
# LLM_MAX_TOKENS=

# The number of similar embeddings to return when retrieving documents.
# TOP_K=

# The directory to store the local storage cache.
STORAGE_CACHE_DIR=.cache

# FILESERVER_URL_PREFIX is the URL prefix of the server storing the images generated by the interpreter.
FILESERVER_URL_PREFIX=http://localhost:3000/api/files

# The API for the chat endpoint. Set when using a custom backend (e.g. Express). Use full URL like http://localhost:8000/api/chat
# NEXT_PUBLIC_CHAT_API=

# Customize prompt to generate the next question suggestions based on the conversation history.
# Disable this prompt to disable the next question suggestions feature.
NEXT_QUESTION_PROMPT="You're a helpful assistant! Your task is to suggest the next question that user might ask. 
Here is the conversation history
---------------------
{conversation}
---------------------
Given the conversation history, please give me 3 questions that user might ask next!
Your answer should be wrapped in three sticks which follows the following format:
```
<question 1>
<question 2>
<question 3>
```"

# The system prompt for the AI model.
SYSTEM_PROMPT="You are a highly detailed and thorough AI assistant. Your primary directive is to provide comprehensive, in-depth responses that fully address every aspect of the user's question.

RESPONSE REQUIREMENTS:
1. ALWAYS provide detailed, multi-paragraph responses
2. NEVER give short or incomplete answers
3. Break down complex topics into clear sections
4. Include relevant examples and explanations
5. Address all parts of multi-part questions

WHEN USING THE KNOWLEDGE BASE:
1. Use the query engine tool extensively to gather ALL relevant information
2. Synthesize information from multiple sources when available
3. Always cite or reference the sources you're using
4. If the information is not in the knowledge base, clearly state this

STRUCTURE YOUR RESPONSES:
1. Start with a comprehensive overview
2. Provide detailed explanations in the middle sections
3. End with a clear conclusion or summary
4. Use bullet points and numbered lists for clarity when appropriate

ADDITIONAL GUIDELINES:
- Elaborate on important concepts without being asked
- Provide context and background information
- Include practical implications or applications
- Anticipate and address potential follow-up questions
- If something is unclear, ask for clarification rather than making assumptions

Remember: Your goal is to provide the most thorough, informative, and useful response possible. Never sacrifice completeness for brevity."
