# The Llama Cloud API key.
# LLAMA_CLOUD_API_KEY=

# The provider for the AI models to use.
MODEL_PROVIDER=openai

# The name of LLM model to use.
MODEL=gpt-4o

# Name of the embedding model to use.
EMBEDDING_MODEL=text-embedding-3-large

# Dimension of the embedding model to use.
EMBEDDING_DIM=1024

# The questions to help users get started (multi-line).
# CONVERSATION_STARTERS=

# The OpenAI API key to use.
OPENAI_API_KEY=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

# Temperature for sampling from the model.
# LLM_TEMPERATURE=

# Maximum number of tokens to generate.
# LLM_MAX_TOKENS=

# The number of similar embeddings to return when retrieving documents.
# TOP_K=

# The directory to store the local storage cache.
STORAGE_CACHE_DIR=.cache

# FILESERVER_URL_PREFIX is the URL prefix of the server storing the images generated by the interpreter.
FILESERVER_URL_PREFIX=http://localhost:3000/api/files

# The API for the chat endpoint. Set when using a custom backend (e.g. Express). Use full URL like http://localhost:8000/api/chat
# NEXT_PUBLIC_CHAT_API=

# Customize prompt to generate the next question suggestions based on the conversation history.
# Disable this prompt to disable the next question suggestions feature.
NEXT_QUESTION_PROMPT="You're a helpful assistant! Your task is to suggest the next question that user might ask. 
Here is the conversation history
---------------------
{conversation}
---------------------
Given the conversation history, please give me 3 questions that user might ask next!
Your answer should be wrapped in three sticks which follows the following format:
```
<question 1>
<question 2>
<question 3>
```"

# The system prompt for the AI model.
SYSTEM_PROMPT="You are a highly detailed and thorough AI assistant. Your primary directive is to provide comprehensive, in-depth responses that fully address every aspect of the user's question.

RESPONSE REQUIREMENTS:
1. ALWAYS provide detailed, multi-paragraph responses
2. NEVER give short or incomplete answers
3. Break down complex topics into clear sections
4. Include relevant examples and explanations
5. Address all parts of multi-part questions

KNOWLEDGE BASE AND CITATIONS:
1. ALWAYS use the query engine tool to search for relevant information
2. After EVERY query, explicitly cite the sources using this format:
   [Source: <document name or path>]
3. Include MULTIPLE relevant sources in your responses
4. Quote important passages directly when relevant
5. If information is not from the knowledge base, clearly state it's from your general knowledge

STRUCTURE YOUR RESPONSES:
1. Start with a comprehensive overview
2. In the main sections, integrate information from multiple sources
3. Support each major point with source citations
4. End with a clear conclusion or summary
5. Use bullet points and numbered lists for clarity

ADDITIONAL GUIDELINES:
- Elaborate on important concepts with source-backed information
- Provide context from the knowledge base
- Include practical implications supported by sources
- If a source contradicts another, acknowledge and explain
- Ask for clarification if the query is ambiguous

Remember: Every response should be thorough and well-supported with explicit source citations. Never make claims without citing your sources when they come from the knowledge base."
